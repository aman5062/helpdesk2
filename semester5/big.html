<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta meta name="viewport" content="width=device-width, user-scalable=no" />
    <title>Helpdesk</title>
</head>
   
<script
	src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js"
	integrity="sha384-7+zCNj/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB"
	crossorigin="anonymous"
></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link
	rel="stylesheet"
	href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.7.2/font/bootstrap-icons.css"
/>
<link rel="icon" href="assets/images/logo.png" type="image/png">
<link rel="stylesheet" type="text/css" href="../assets/css/style.css" />
<script src="../assets/js/script.js"></script>
<style>
 
  </style>
<body onload="waterm()"> 
  <header class="navbar navbar-expand-md d-flex flex-wrap justify-content-center mt-2 p-2 mb-2 border-bottom">
   <div id="top_bar">
    <a href="#" class="d-flex align-items-center mb-3 mb-md-0 me-md-auto link-body-emphasis text-decoration-none">
      <img src="../assets/images/logo.png" id="imglogo">
      <span class="fs-4 mr-5 lo"><h2 class="bold-text">Helpdesk</h2></span>
    </a>
   </div>
    <div class="container-fluid" id="sec_nav">
      <button class="navbar-toggler" type="button" onclick="openLeftSidebar()">
      <span class="navbar-toggler-icon"></span>
      </button>
     <div id="leftSidebar" class="sidebar-left">
      <a href="javascript:void(0)" class="closebtn" onclick="closeLeftSidebar()">&times;</a>
      <h2>semester 5</h2>
      <a href="../semester5/index.html">Software tech.</a>
      <a href="../semester5/formal.html">Formal lang.</a>
      <a href="../semester5/ai.html">AI</a>
      <a href="../semester5/ml.html">ML</a>
      <a href="../semester5/const.html">Indian Const.</a>
      <a href="../semester5/comp_netw.html">Comp. Networks</a>
      <a href="../semester5/big.html" class="active">Big Data</a>
      <a href="../semester5/cloud.html">Cloud Computing</a>

      <h2>semester 6</h2>
      <a href="../semester6/index.html">Digital Image</a>
      <a href="../semester6/Compiler.html">Compiler Design</a>
      <a href="../semester6/Computational.html">Computational Intell.</a>
      <a href="../semester6/ds_big_data.html">DS and Big data</a>
      <a href="../semester6/computer_graphics.html">Computer Graphics</a>
      <a href="../semester6/python_da.html">Python for DA</a>
      <a href="../semester6/ds.html">Data Science</a>
     
  </div>
  <div class="semester">semester-5</div>

      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" id="upper_menu_btn" data-bs-target="#collapsibleNavbar">
 <i class="fa fa-arrow-down" aria-hidden="true"></i>      </button>
      <div class="collapse navbar-collapse" id="collapsibleNavbar" >
        <ul class="nav nav-pills navbar-nav ms-auto" id="myNav">
          <!-- 1st Year -->
          <li class="nav-item">
            <a class="nav-link" href="../semester1/index.html">1st Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester3/index.html">2nd Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester5/index.html">3rd Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../semester7/index.html">4th Year</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="../NPTEL/index.html">NPTEL</a>
          </li>
        </ul>
      </div>
    </div>
  </header>
  
  
    <div id="body">
      <div class="heading_name">Big Data</div>
      <div id="watermark">@Debuggers</div>

      <div id="up">
        <a href="#" id="goToTopButton" class="go-to-top-button">
          <span><i class="fa fa-arrow-up" aria-hidden="true" id="arrow"></i></span>
      </a>
      </div>  
     
      <h3>Digital Data and Big Data Concepts</h3>

      <h4>1. Types of Digital Data</h4>
      <p><strong>Digital Data</strong> refers to data that is represented in a binary format (0s and 1s) and can be processed by computers. It can be categorized into several types:</p>
      <ul>
          <li><strong>Structured Data:</strong> Data that is organized in a fixed format, such as databases and spreadsheets. Examples include customer names, addresses, and transactions.</li>
          <li><strong>Unstructured Data:</strong> Data that does not have a predefined format or structure. Examples include text documents, emails, social media posts, and multimedia files (images, videos).</li>
          <li><strong>Semi-Structured Data:</strong> Data that has some organizational properties but does not fit into a rigid structure. Examples include XML files, JSON data, and logs.</li>
      </ul>
  
      <h4>2. Introduction to Big Data</h4>
      <p><strong>Big Data</strong> refers to large and complex datasets that are difficult to process using traditional data processing tools. Characteristics of Big Data include:</p>
      <ul>
          <li><strong>Volume:</strong> The sheer amount of data being generated.</li>
          <li><strong>Velocity:</strong> The speed at which data is generated and processed.</li>
          <li><strong>Variety:</strong> The different types of data (structured, unstructured, semi-structured).</li>
          <li><strong>Veracity:</strong> The uncertainty or quality of the data.</li>
      </ul>
  
      <h4>3. Big Data Analytics</h4>
      <p><strong>Big Data Analytics</strong> involves using advanced analytical techniques and technologies to extract insights from large datasets. It includes:</p>
      <ul>
          <li><strong>Descriptive Analytics:</strong> Analyzing historical data to understand what happened.</li>
          <li><strong>Predictive Analytics:</strong> Using data to predict future trends and behaviors.</li>
          <li><strong>Prescriptive Analytics:</strong> Providing recommendations for actions based on data analysis.</li>
      </ul>
  
      <h4>4. History of Hadoop</h4>
      <p><strong>Hadoop</strong> is an open-source framework for distributed storage and processing of large datasets. Its history includes:</p>
      <ul>
          <li><strong>2005:</strong> Hadoop was created by Doug Cutting and Mike Cafarella as part of the Nutch project.</li>
          <li><strong>2006:</strong> Hadoop became a top-level project at the Apache Software Foundation.</li>
          <li><strong>2011:</strong> The Hadoop ecosystem grew with the introduction of tools like HBase, Hive, and Pig.</li>
      </ul>
  
      <h4>5. Apache Hadoop</h4>
      <p><strong>Apache Hadoop</strong> is a framework that enables distributed processing of large datasets across clusters of computers. Key components include:</p>
      <ul>
          <li><strong>Hadoop Distributed File System (HDFS):</strong> A scalable and fault-tolerant file system for storing large data files.</li>
          <li><strong>MapReduce:</strong> A programming model for processing large datasets in parallel.</li>
          <li><strong>YARN (Yet Another Resource Negotiator):</strong> A resource management layer that schedules and manages resources in the Hadoop cluster.</li>
      </ul>
  
      <h4>6. Analyzing Data with Unix Tools</h4>
      <p><strong>Unix Tools</strong> are command-line utilities used for processing and analyzing data. Some commonly used tools include:</p>
      <ul>
          <li><strong>grep:</strong> Searches for patterns in text files.</li>
          <li><strong>awk:</strong> A programming language for pattern scanning and processing.</li>
          <li><strong>sed:</strong> A stream editor for filtering and transforming text.</li>
          <li><strong>sort:</strong> Sorts lines of text files.</li>
          <li><strong>cut:</strong> Removes sections from each line of files.</li>
      </ul>
  
      <h4>7. Analyzing Data with Hadoop</h4>
      <p><strong>Analyzing Data with Hadoop</strong> involves using Hadoop's ecosystem to process and analyze large datasets. Techniques include:</p>
      <ul>
          <li><strong>MapReduce Jobs:</strong> Writing MapReduce programs to process data in parallel across a Hadoop cluster.</li>
          <li><strong>Hive:</strong> A data warehouse tool that provides an SQL-like interface for querying and managing data stored in HDFS.</li>
          <li><strong>Pig:</strong> A high-level scripting language for processing and analyzing data in Hadoop.</li>
          <li><strong>HBase:</strong> A distributed, scalable database that runs on top of HDFS and provides real-time access to data.</li>
      </ul>
      <h3>Databases and Big Data Concepts</h3>

      <h4>1. Databases and Relational Algebra</h4>
      <p><strong>Databases</strong> are structured collections of data that can be easily accessed, managed, and updated. The relational model organizes data into tables (relations) with rows and columns. <strong>Relational Algebra</strong> is a theoretical framework for querying and manipulating relational databases. It includes operations such as:</p>
      <ul>
          <li><strong>Select:</strong> Retrieves rows that satisfy a given condition.</li>
          <li><strong>Project:</strong> Retrieves specific columns from a table.</li>
          <li><strong>Join:</strong> Combines rows from two or more tables based on a related column.</li>
          <li><strong>Union:</strong> Combines the results of two queries, removing duplicates.</li>
          <li><strong>Difference:</strong> Retrieves rows from one table that are not in another.</li>
      </ul>
  
      <h4>2. Parallel Databases</h4>
      <p><strong>Parallel Databases</strong> use multiple processors to perform operations on large datasets in parallel, improving performance and scalability. Key aspects include:</p>
      <ul>
          <li><strong>Parallel Query Processing:</strong> Distributing the execution of a query across multiple processors to speed up response time.</li>
          <li><strong>In-Database Analytics:</strong> Performing analytical operations within the database system itself, reducing the need to move data.</li>
      </ul>
  
      <h4>3. MapReduce</h4>
      <p><strong>MapReduce</strong> is a programming model used for processing and generating large datasets. It consists of two main phases:</p>
      <ul>
          <li><strong>Map:</strong> Processes input data and produces intermediate key-value pairs.</li>
          <li><strong>Reduce:</strong> Aggregates intermediate data based on the key to produce the final output.</li>
      </ul>
  
      <h4>4. Hadoop</h4>
      <p><strong>Hadoop</strong> is an open-source framework that supports the distributed processing of large datasets across clusters of computers. Key components include:</p>
      <ul>
          <li><strong>HDFS (Hadoop Distributed File System):</strong> A scalable and fault-tolerant file system for storing large files across multiple machines.</li>
          <li><strong>MapReduce:</strong> A programming model for processing data in parallel across a Hadoop cluster.</li>
      </ul>
  
      <h4>5. The Design of HDFS</h4>
      <p><strong>HDFS</strong> is designed to store vast amounts of data across multiple servers while providing high throughput and fault tolerance. Key concepts include:</p>
      <ul>
          <li><strong>Blocks:</strong> Files are split into fixed-size blocks, which are replicated across multiple nodes.</li>
          <li><strong>NameNode:</strong> Manages the metadata and namespace of the file system.</li>
          <li><strong>DataNodes:</strong> Store the actual data blocks and handle read and write requests.</li>
      </ul>
  
      <h4>6. Command Line Interface</h4>
      <p><strong>HDFS Command Line Interface (CLI)</strong> allows users to interact with the Hadoop file system. Common commands include:</p>
      <ul>
          <li><strong>hdfs dfs -ls:</strong> Lists files and directories in HDFS.</li>
          <li><strong>hdfs dfs -put:</strong> Uploads files to HDFS.</li>
          <li><strong>hdfs dfs -get:</strong> Downloads files from HDFS.</li>
      </ul>
  
      <h4>7. Hadoop File System Interface and Relationship to Databases</h4>
      <p><strong>Hadoop File System Interface</strong> provides access to HDFS, which can be integrated with traditional databases for analytics and data processing. Differences between HDFS and traditional databases include:</p>
      <ul>
          <li><strong>Schema:</strong> HDFS is schema-less, while traditional databases have a fixed schema.</li>
          <li><strong>Query Language:</strong> HDFS uses MapReduce, while traditional databases use SQL.</li>
          <li><strong>Data Storage:</strong> HDFS is optimized for large-scale data processing, while traditional databases are optimized for transaction processing.</li>
      </ul>
  
      <h4>8. Algorithms, Extensions, and Languages</h4>
      <p><strong>Algorithms</strong> used in Hadoop include sorting, filtering, and aggregating data in MapReduce jobs. <strong>Extensions</strong> such as Hive and Pig provide higher-level abstractions for querying and processing data. <strong>Languages</strong> used include:</p>
      <ul>
          <li><strong>Java:</strong> Primary language for writing MapReduce programs.</li>
          <li><strong>SQL:</strong> Used with Hive for querying data in HDFS.</li>
          <li><strong>Pig Latin:</strong> A scripting language for processing data in Pig.</li>
      </ul>
  
      <h4>9. Key-Value Stores and NoSQL</h4>
      <p><strong>Key-Value Stores</strong> are a type of NoSQL database where each data item is stored as a key-value pair. Examples include:</p>
      <ul>
          <li><strong>Redis:</strong> An in-memory key-value store.</li>
          <li><strong>Riak:</strong> A distributed key-value store with high availability.</li>
      </ul>
      <p><strong>NoSQL Databases</strong> are designed to handle unstructured and semi-structured data. They include:</p>
      <ul>
          <li><strong>Document Stores:</strong> Store data as documents (e.g., MongoDB).</li>
          <li><strong>Column Stores:</strong> Store data in columns rather than rows (e.g., Cassandra).</li>
          <li><strong>Graph Databases:</strong> Store data as nodes and edges (e.g., Neo4j).</li>
      </ul>
      <p><strong>Tradeoffs between SQL and NoSQL:</strong></p>
      <ul>
          <li><strong>SQL:</strong> Provides ACID properties (Atomicity, Consistency, Isolation, Durability) and is suitable for structured data and complex queries.</li>
          <li><strong>NoSQL:</strong> Offers flexibility in data models, scalability, and high performance for large-scale data and real-time applications.</li>
      </ul>
    <hr>
    <center>
    Some Important Questions
    </center>
    <hr>
    <h3>Q: What do you mean by statistical modelling? Explain its benefits and limitations.</h3>
    <p><strong>A:</strong><br>
    Statistical modelling is the process of using mathematical equations to represent relationships between variables within a dataset. It helps analyze trends, make predictions, and understand patterns.</p>
    <p><strong>Benefits:</strong><br>
    1. Identifies trends and patterns in data.<br>
    2. Provides insights into relationships between variables.<br>
    3. Supports decision-making through predictive analysis.</p>
    <p><strong>Limitations:</strong><br>
    1. Assumes underlying data distributions, which may not match real-world data.<br>
    2. Sensitive to outliers and missing data.<br>
    3. Requires expertise in statistics and data interpretation.</p>

    <h3>Q: Define machine learning and explain its benefits. Compare it with AI.</h3>
    <p><strong>A:</strong><br>
    <strong>Machine Learning:</strong> Machine learning (ML) is a subset of artificial intelligence (AI) where algorithms learn patterns from data and improve their performance without explicit programming.</p>
    <p><strong>Benefits of ML:</strong><br>
    1. Automates decision-making processes.<br>
    2. Increases accuracy with more data.<br>
    3. Solves complex problems like image recognition and language processing.</p>
    <p><strong>Comparison with AI:</strong><br>
    - <strong>ML:</strong> Focuses on learning from data to make predictions.<br>
    - <strong>AI:</strong> Encompasses ML and other techniques like rule-based systems to simulate human intelligence.<br>
    - <strong>AI is broader</strong> and includes reasoning, planning, and problem-solving, while ML is primarily data-driven.</p>

    <h3>Q: What do you mean by supervised learning? How does it differ from unsupervised learning?</h3>
    <p><strong>A:</strong><br>
    <strong>Supervised Learning:</strong> A type of machine learning where the model is trained on labeled data (input-output pairs). The goal is to predict outputs for new inputs based on training.</p>
    <p><strong>Unsupervised Learning:</strong> A type of machine learning where the model works with unlabeled data, finding hidden structures, patterns, or clusters.</p>
    <p><strong>Key Differences:</strong></p>
    <table border="1">
        <tr>
            <th>Aspect</th>
            <th>Supervised Learning</th>
            <th>Unsupervised Learning</th>
        </tr>
        <tr>
            <td>Training Data</td>
            <td>Labeled</td>
            <td>Unlabeled</td>
        </tr>
        <tr>
            <td>Goal</td>
            <td>Predict specific outcomes</td>
            <td>Discover hidden patterns</td>
        </tr>
        <tr>
            <td>Example Tasks</td>
            <td>Classification, Regression</td>
            <td>Clustering, Dimensionality Reduction</td>
        </tr>
    </table>

    <h3>Q: Explain classification, regression, KNN, and gradient descent with examples.</h3>
    <p><strong>A:</strong><br>
    <strong>1. Classification:</strong> Predicts discrete labels or categories.<br>
    Example: Email spam detection (Spam/Not Spam).</p>
    <p><strong>2. Regression:</strong> Predicts continuous values.<br>
    Example: Predicting house prices based on size and location.</p>
    <p><strong>3. K-Nearest Neighbors (KNN):</strong> A simple algorithm that classifies a data point based on the majority class of its k-nearest neighbors.<br>
    Example: Classifying whether a fruit is an apple or orange based on size and color.</p>
    <p><strong>4. Gradient Descent:</strong> An optimization algorithm used to minimize the error of a model by iteratively adjusting weights.<br>
    Example: Training a neural network to improve accuracy.</p>

    <h3>Q: What do you mean by data visualization? Explain data privacy involved during data visualization.</h3>
    <p><strong>A:</strong><br>
    <strong>Data Visualization:</strong> The graphical representation of data using charts, graphs, and plots to make insights easier to interpret.</p>
    <p><strong>Data Privacy:</strong> During visualization, sensitive data can be exposed. Safeguarding privacy involves:</p>
    <ul>
        <li>Anonymizing datasets to remove identifiable information.</li>
        <li>Using aggregate data instead of individual-level data.</li>
        <li>Implementing strict access controls and encryption.</li>
    </ul>

    <h3>Q: Explain various graph traversal techniques.</h3>
    <p><strong>A:</strong><br>
    <strong>1. Breadth-First Search (BFS):</strong> Explores all neighbors at the current depth before moving deeper.<br>
    Example: Shortest path in an unweighted graph.</p>
    <p><strong>2. Depth-First Search (DFS):</strong> Explores as far as possible along each branch before backtracking.<br>
    Example: Maze-solving algorithms.</p>

    <h3>Q: Explain community detection and PageRank in graph analysis.</h3>
    <p><strong>A:</strong><br>
    <strong>1. Community Detection:</strong> Identifies clusters of closely connected nodes in a graph.<br>
    Example: Finding groups of friends in a social network.</p>
    <p><strong>2. PageRank:</strong> A ranking algorithm that evaluates the importance of nodes (e.g., web pages) based on link structure.<br>
    Example: Used by Google to rank web pages in search results.</p>

    <h3>Q: Explain the various types of data with examples.</h3>
    <p><strong>A:</strong><br>
    <strong>1. Structured Data:</strong> Organized into rows and columns.<br>
    Example: Excel sheets, SQL databases.</p>
    <p><strong>2. Unstructured Data:</strong> Does not have a predefined format.<br>
    Example: Text, images, videos.</p>
    <p><strong>3. Semi-Structured Data:</strong> Has some organization but not rigidly structured.<br>
    Example: JSON, XML files.</p>

    <h3>Q: What do you mean by big data analysis? Why do we use Hadoop? Explain HDFS design.</h3>
    <p><strong>A:</strong><br>
    <strong>Big Data Analysis:</strong> The process of analyzing vast volumes of data to uncover patterns, trends, and insights.</p>
    <p><strong>Why Hadoop?</strong><br>
    - Handles large-scale data efficiently.<br>
    - Distributed and fault-tolerant storage and processing.</p>
    <p><strong>HDFS (Hadoop Distributed File System) Design:</strong><br>
    - Stores data across multiple nodes.<br>
    - Splits large files into blocks and distributes them.<br>
    - Ensures redundancy with replication.</p>

    <h3>Q: Explain MapReduce in data analytics.</h3>
    <p><strong>A:</strong><br>
    MapReduce is a programming model for processing large datasets in parallel across distributed systems.</p>
    <p><strong>Map Phase:</strong> Splits data into smaller chunks and processes them in parallel.<br>
    <strong>Reduce Phase:</strong> Aggregates and combines results from the map phase.<br>
    Example: Counting the frequency of words in a large document.</p>

    <h3>Q: Explain the concept behind relational database systems.</h3>
    <p><strong>A:</strong><br>
    A relational database organizes data into tables (relations) with rows and columns, using keys to establish relationships.<br>
    Example: SQL databases like MySQL and PostgreSQL.</p>

    <h3>Q: What are parallel databases? How do they differ from conventional databases?</h3>
    <p><strong>A:</strong><br>
    <strong>Parallel Databases:</strong> Use multiple processors to execute queries and manage large datasets efficiently.</p>
    <p><strong>Differences:</strong></p>
    <table border="1">
        <tr>
            <th>Aspect</th>
            <th>Parallel Databases</th>
            <th>Conventional Databases</th>
        </tr>
        <tr>
            <td>Performance</td>
            <td>High (due to parallelism)</td>
            <td>Slower for large datasets</td>
        </tr>
        <tr>
            <td>Scalability</td>
            <td>Easier to scale</td>
            <td>Limited scalability</td>
        </tr>
    </table>

    <h3>Q: Explain any two data analytics tools used in big data.</h3>
    <p><strong>A:</strong><br>
    1. <strong>Apache Spark:</strong> A distributed processing system for large-scale data analytics, offering in-memory computation.<br>
    2. <strong>Tableau:</strong> A visualization tool for analyzing and presenting data interactively.</p>

    <h3>Q: What do you mean by data manipulation? Explain.</h3>
    <p><strong>A:</strong><br>
    Data manipulation refers to transforming and organizing data to make it more useful. This includes tasks like filtering, sorting, aggregating, and cleaning.<br>
    Example: Converting dates to a standard format for analysis.</p>

    <h3>Q: Explain the DBMS architecture with an example.</h3>
    <p><strong>A:</strong><br>
    <strong>Three-Tier DBMS Architecture:</strong><br>
    1. <strong>Presentation Layer (User Interface):</strong> Interacts with the user.<br>
    2. <strong>Application Layer:</strong> Handles business logic.<br>
    3. <strong>Database Layer:</strong> Stores and retrieves data.<br>
    Example: A banking system where users interact with an application to retrieve account data from a database.</p>

    <h3>Q: Compare OLAP and OLTP databases.</h3>
    <p><strong>A:</strong><br>
    <table border="1">
        <tr>
            <th>Aspect</th>
            <th>OLAP (Online Analytical Processing)</th>
            <th>OLTP (Online Transaction Processing)</th>
        </tr>
        <tr>
            <td>Purpose</td>
            <td>Analytics and reporting</td>
            <td>Day-to-day transactions</td>
        </tr>
        <tr>
            <td>Data Type</td>
            <td>Historical</td>
            <td>Current</td>
        </tr>
        <tr>
            <td>Examples</td>
            <td>Business Intelligence tools</td>
            <td>Banking systems</td>
        </tr>
    </table>
    <h3>Q: What do you mean by the term data analytics? Explain with an example.</h3>
    <p><strong>A:</strong><br>
    Data analytics involves examining raw data to draw conclusions and make decisions.<br>
    Example: Analyzing sales data to identify top-performing products.</p>

    <h3>Q: Define digital data and explain its various types.</h3>
    <p><strong>A:</strong><br>
    Digital Data: Data stored in binary format, readable by machines.</p>
    <ul>
        <li><strong>Text Data:</strong> Documents, emails.</li>
        <li><strong>Audio Data:</strong> MP3 files, podcasts.</li>
        <li><strong>Image Data:</strong> JPEG, PNG files.</li>
        <li><strong>Video Data:</strong> MP4, AVI files.</li>
    </ul>

    <h3>Q: Compare data and big data.</h3>
    <p><strong>A:</strong><br>
    <table border="1">
        <tr>
            <th>Aspect</th>
            <th>Data</th>
            <th>Big Data</th>
        </tr>
        <tr>
            <td>Size</td>
            <td>Small to medium</td>
            <td>Extremely large</td>
        </tr>
        <tr>
            <td>Processing Tools</td>
            <td>Standard tools</td>
            <td>Advanced tools like Hadoop, Spark</td>
        </tr>
    </table>
    </p>

    <h3>Q: Explain data analytics with Apache Hadoop.</h3>
    <p><strong>A:</strong><br>
    Hadoop enables distributed storage and processing of large datasets using tools like HDFS and MapReduce. It provides scalability and fault tolerance for data analytics tasks.</p>

    <h3>Q: Explain the concept behind parallel processing in DB systems.</h3>
    <p><strong>A:</strong><br>
    Parallel processing divides tasks into smaller sub-tasks, executed concurrently using multiple processors. It enhances query execution speed and scalability.</p>

    <h3>Q: Explain any five data analytics tools.</h3>
    <p><strong>A:</strong><br>
    1. <strong>Apache Spark:</strong> Distributed computing framework.<br>
    2. <strong>Tableau:</strong> Data visualization tool.<br>
    3. <strong>R:</strong> Statistical analysis and visualization.<br>
    4. <strong>Python (Pandas, NumPy):</strong> Versatile programming tools for data manipulation and analysis.<br>
    5. <strong>Excel:</strong> Simple analysis for small datasets.</p>


        </body>
</html>